# -*- coding: utf-8 -*-
"""DA2-SVD++MatrixFactorization.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hMRn23f1z1AqrupNmNqjxMsgmxeu1GyR

# **Adding library**
"""

#adding library
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
#import random for random between a and b (not include a, b)
import random

"""# **Pull data directly and unzip from grouplens website**"""

DATASET_LINK='http://files.grouplens.org/datasets/movielens/ml-100k.zip'
!wget -nc http://files.grouplens.org/datasets/movielens/ml-100k.zip
!unzip -n ml-100k.zip

"""# **Describe data, statistics data in general way**

## *Describe*
"""

# Viewing u.data file
column_names1 = ['user id','movie id','rating','timestamp']
df = pd.read_csv('ml-100k/u.data', sep='\t',header=None,names=column_names1)
df.head()

#check min, max rating and count how many the distincts value
print("rating:")
print(df.rating.max())
print(df.rating.min())
print(df.rating.value_counts())

#check how many the distincts value of users id
print("user:")
print(df["user id"].value_counts())
#check how many the distincts value of video
print("video:")
print(df["movie id"].value_counts())

df['rating'].describe()

"""## *Statistics and charts*"""

plt.hist(df['rating'],log=True);
plt.plot();
plt.show();

"""# **Offline phase**

## *Build matrix factorization using svd++*
"""

#@title Default title text
class SVDpp:
# Khởi tạo các biến cho class SVDpp
# matrixDataSet là tập dữ liệu đưa vào (tập train), numFactor là số factor ẩn
# bi là bias của item i, bu là bias của item u
# qi là dictionary chứa những key (id item) và giá trị của key là ma trận (1 cột) 
#   numFactor số random trong nữa khoảng [0,1)
# qu là dictionary chứa những key (id user) và giá trị của key là ma trận (1 cột)
#   numFactor số random trong nữa khoảng [0,1)
# yi là dictionary chứa những key (id item) và giá trị của key là ma trận (1 cột)
#   numFactor số 0.1; đây là ma trận những nhân tố ẩn.
# avg là trung bình rating của matrixDataSet đưa vào.
# u_dict là dictionary chứa các key là user id và value là danh sách các item id
#   mà user đó đã rate.
    def __init__(self, matrixDataSet, numFactor=20):
        self.matrixDataSet = np.array(matrixDataSet)
        self.numFactor = numFactor
        self.bi = {}
        self.bu = {}
        self.qi = {}
        self.pu = {}
        self.avg = np.mean(self.matrixDataSet[:, 2])
        self.yi = {}
        self.u_dict = {}
        for i in range(self.matrixDataSet.shape[0]):
            user_id = self.matrixDataSet[i, 0]
            item_id = self.matrixDataSet[i, 1]
            self.u_dict.setdefault(user_id, [])
            self.u_dict[user_id].append(item_id)
            self.bi.setdefault(item_id, 0)
            self.bu.setdefault(user_id, 0)
            self.qi.setdefault(item_id, np.random.random((self.numFactor, 1)))
            self.pu.setdefault(user_id, np.random.random((self.numFactor, 1)))
            self.yi.setdefault(item_id, np.zeros((self.numFactor, 1)) + .1)

# Tính căn bậc 2 của Nu và Σyj. It used for predict, train method
# Nu is the amount of item which user rated. Get from u_dict
# userImplicitFactor is the result of sqrt(Nu) multiply Σyj
    def getNuYj(self, user_id, item_id):
            Nu = self.u_dict[user_id]
            numItemOfNu = len(Nu)
            sqrt_Nu = np.sqrt(numItemOfNu)
            y_u = np.zeros((self.numFactor, 1))
            if numItemOfNu == 0:
                userImplicitFactor = y_u
            else:
                for idItem in Nu:
                    y_u += self.yi[idItem]
                userImplicitFactor = y_u / sqrt_Nu

            return userImplicitFactor, sqrt_Nu

# Hàm predict để predict rating
# Phương thức setdefault là dành cho những item, user mới vào hệ thống
#   và thiết lập bi, bu, qi, pu và yi bằng 0. Khởi tạo mảng item rỗng mà user id
#   đã rate (chưa có gì)
# Bởi vì score nằm trong đoạn từ 1 đến 5, khi điểm lớn hơn 5 trả về 5 
# hoặc nhỏ hơn 1, 1 sẽ được trả về.
    def predict(self, user_id, item_id):  
        self.bi.setdefault(item_id, 0)
        self.bu.setdefault(user_id, 0)
        self.qi.setdefault(item_id, np.zeros((self.numFactor, 1)))
        self.pu.setdefault(user_id, np.zeros((self.numFactor, 1)))
        self.yi.setdefault(item_id, np.zeros((self.numFactor, 1)))
        self.u_dict.setdefault(user_id, [])
        userImplicitFactor, sqrt_Nu = self.getNuYj(user_id, item_id)
        rating = self.avg + self.bi[item_id] + self.bu[user_id] + np.sum(
            self.qi[item_id] * (self.pu[user_id] + userImplicitFactor))
        if rating > 5:
            rating = 5
        if rating < 1:
            rating = 1
        return rating

# Train function which is build by the matrix factorization and the svd++
# Lambda thay cho lambda vì bị lỗi do trùng với anonymous function (lambda).
# At the step 2 of docx, we get all pair of user, item, but here, we use number
#   of the rating in dataset source and random to take by np.random.permutation()
#   method which references n number and return an contigent array of the n number from 0 to n-1
# Get all of rating in dataset: self.matrixDataSet.shape[0]
    def train(self, epochs=20, alpha=0.005, Lambda=0.02):
        for epoch in range(epochs):
            print('epoch', epoch + 1, 'is running')
            Yui = np.random.permutation(self.matrixDataSet.shape[0])
            # Stochastic Gradient Descent
            rmse = 0.0
            for i in range(self.matrixDataSet.shape[0]):
                j = Yui[i]
                user_id = self.matrixDataSet[j, 0]
                item_id = self.matrixDataSet[j, 1]
                rating = self.matrixDataSet[j, 2]
                predict = self.predict(user_id, item_id)
                userImplicitFactor, sqrt_Nu = self.getNuYj(user_id, item_id)
                eui = rating - predict #step 7
                rmse += eui ** 2
                tempPu = self.pu[user_id] - alpha * (Lambda * self.pu[user_id] - eui * self.qi[item_id])
                tempQi = self.qi[item_id] - alpha * (Lambda * self.qi[item_id] - eui * (self.pu[user_id] + userImplicitFactor))
                self.bu[user_id] -= alpha * (Lambda * self.bu[user_id] - eui) #step 10
                self.bi[item_id] -= alpha * (Lambda * self.bi[item_id] - eui)
                self.pu[user_id] = tempPu
                self.qi[item_id] = tempQi
                for j in self.u_dict[user_id]: #step 14
                    self.yi[j] -= alpha * (Lambda * self.yi[j] - eui * self.qi[j] / sqrt_Nu)
            print('rmse: ', np.sqrt(rmse / self.matrixDataSet.shape[0]))


    def test(self, test_data):
        test_data = np.array(test_data)
        print('test data size: ', test_data.shape)
        rmse = 0.0
        for i in range(test_data.shape[0]):
            user_id = test_data[i, 0]
            item_id = test_data[i, 1]
            rating = test_data[i, 2]
            eui = rating - self.predict(user_id, item_id)
            rmse += eui ** 2
        print('rmse of test data is: ', np.sqrt(rmse / test_data.shape[0]))
        return np.sqrt(rmse / test_data.shape[0])

"""## *Preparing data to train*

### - Random (or load if right) data to train and test
"""

column_names1 = ['user id','movie id','rating','timestamp']
datatrain = pd.read_csv('/content/ml-100k/u1.base', sep='\t',header=None,names=column_names1)
datatest = pd.read_csv('/content/ml-100k/u1.test', sep='\t',header=None,names=column_names1)

"""### - Check, filter data"""

## Lấy dữ liệu và lọc dữ liệu (xóa duplicate, null, NaN)
datatrain.dropna(inplace=True)
datatrain.drop_duplicates(inplace=True)
datatest.dropna(inplace=True)
datatest.drop_duplicates(inplace=True)


## Lấy dữ liệu gồm title, id phim từ u.item và lọc
col = 'movie id | movie title | release date | video release date | IMDb URL | unknown | Action '
col+= '| Adventure | Animation | Children | Comedy | Crime | Documentary | Drama | Fantasy | Film-Noir '
col+= '| Horror | Musical | Mystery | Romance | Sci-Fi | Thriller | War | Western'
colItem = col.split(' | ')
movieItem = pd.read_csv('ml-100k/u.item', 
                        sep='|',header=None,names=colItem,encoding='latin-1')
movieItem = movieItem[['movie id','movie title']]
movieItem.dropna(inplace=True)
movieItem.drop_duplicates(inplace=True)

"""## *Training*

### 1. Predict before train (testing)
"""

numFactor = 20
beforetrain = SVDpp(datatrain, numFactor)

#196	242	3	881250949
#186	302	3	891717742
#22	377	1	878887116
print (beforetrain.predict(196, 242))
print (beforetrain.predict(186	,302))
print (beforetrain.predict(22,	377))

"""### 2. To train
epochs=20, numFactor=10,
times~=40'
"""

numFactor = 10
model = SVDpp(datatrain, numFactor)
model.train(epochs=5)

"""### 3. After trained (testing)"""

print (datatest.shape[0])
test_data = np.array(datatest)
print('test data size', datatest.shape[0])
table={}
table[numFactor] = [model.test(datatest)]
# Create DataFrame
df = pd.DataFrame(table)

# Print the output.
print(df)

# predict rating
#196	242	3
#186	302	3
#22	377	1
print (model.predict(196, 242))
print (model.predict(186	,302))
print (model.predict(22,	377))

#1	6	5	887431973
#1	10	3	875693118
print("===================")
print (model.predict(1	,6))
print (model.predict(1,	10))

#247	50	5	893097024
#328	470	4	885046537
print("===================")
print (model.predict(247	,50))
print (model.predict(328,	470))

"""Cho thấy việc predict ngày càng chính xác hơn nếu chúng ta build với epoch, numfactor cao hơn (không quá cao). Epoch cỡ 100-200, numFactor cỡ 20!?

## *Train more*

### *Train thay đổi epochs, numFactor trên 1 tập dữ liệu train u1.base*

epochs=50, numFactor=20 => times ~= 1h30
"""

modelFifTwe = SVDpp(datatrain, numFactor=20)
modelFifTwe.train(epochs=50)

# predict rating
#196	242	3
#186	302	3
#22	377	1
print (modelFifTwe.predict(196, 242))
print (modelFifTwe.predict(186	,302))
print (modelFifTwe.predict(22,	377))

#1	6	5	
#1	10	3	
print("===================")
print (modelFifTwe.predict(1	,6))
print (modelFifTwe.predict(1,	10))

#247	50	5	
#328	470	4	
print("===================")
print (modelFifTwe.predict(247	,50))
print (modelFifTwe.predict(328,	470))

"""epochs=100 numFactor=20"""

modelHundFif = SVDpp(datatrain, numFactor=20)
modelHundFif.train(epochs=100)

# predict rating
#196	242	3
#186	302	3
#22	377	1
print (modelHundFif.predict(196, 242))
print (modelHundFif.predict(186	,302))
print (modelHundFif.predict(22,	377))

#1	6	5	
#1	10	3	
print("===================")
print (modelHundFif.predict(1	,6))
print (modelHundFif.predict(1,	10))

#247	50	5	
#328	470	4	
print("===================")
print (modelHundFif.predict(247	,50))
print (modelHundFif.predict(328,	470))

"""*Cho thấy build với epochs lớn, và factor lớn thì độ chính xác càng lớn. Nhưng trái lại thời gian build rất lâu; 85 epoch, 20 factor ~= 3h*

### A testing chains
"""

modelTwTwChains = SVDpp(datatrain, numFactor=20)
modelTwTwChains.train(epochs=10)
modelTwTwChains.train(epochs=20)
modelTwTwChains.train(epochs=20)

# predict rating
#196	242	3
#186	302	3
#22	377	1
print (modelTwTwChains.predict(196, 242))
print (modelTwTwChains.predict(186	,302))
print (modelTwTwChains.predict(22,	377))

#1	6	5	
#1	10	3	
print("===================")
print (modelTwTwChains.predict(1	,6))
print (modelTwTwChains.predict(1,	10))

#247	50	5	
#328	470	4	
print("===================")
print (modelTwTwChains.predict(247	,50))
print (modelTwTwChains.predict(328,	470))

"""# Online phase - Recommend films"""

#model = SDVpp(), above
userid=1
amountMovie=3

def checkItemRated(itemid, userid, model):
  listItem = model.u_dict[userid]
  for item in listItem:
    if item == itemid:
      return True
  return False

def recommendFilm(model, userid, amountMovieSystem=1682, amountMovie=3):
  i=1
  countItemRated=0
  bestMovies = {}
  while i <= amountMovieSystem:
    if checkItemRated(i, userid, model):
      #print("item is rated: ", i)
      i+=1
      countItemRated+=1
      continue
    bestMovies[i]=model.predict(userid, i)
    #print("item is not rated", i, " with predict", bestMovies[i])
    i += 1
  sortedBestMovies = sorted(bestMovies.items(), key=lambda x: x[1], reverse=True)
  print("=======================================")
  print("bias:", model.bu[userid])
  print("number of rated:", countItemRated)
  return sortedBestMovies[0:amountMovie]

print("model", recommendFilm(model, 1))
print("modelFifTwe",recommendFilm(modelFifTwe, 1))
#print("modelTwTwChains",recommendFilm(modelTwTwChains, 1))
print("modelHundFif",recommendFilm(modelHundFif, 1))